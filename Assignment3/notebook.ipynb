{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afeka - ML3 - Titanic\n",
    "\n",
    "Noam Levi  \n",
    "205530611  \n",
    "[Kaggle Profile](https://www.kaggle.com/noamlevi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be working on the [Titanic dataset](https://www.kaggle.com/c/titanic/data) from the [kaggle competition](https://www.kaggle.com/c/titanic).  \n",
    "\n",
    "This is a continued work from `Assignment1`.\n",
    "\n",
    "---\n",
    "\n",
    "Roadmap:\n",
    "- [Data Exploration](#Data-Exploration) and Data Visualising - *from `Assignment1`*\n",
    "- [Data Cleaning](#Data-Cleaning), handling missing data in our df using different methods - *from `Assignment1`*\n",
    "- [Feature Engineering](#Feature-Engineering), creating/choosing the right features for a better ML model - *from `Assignment1`*\n",
    "- [Training & Model Comparing](#Training-&-Model-Comparing), Fitting a linear model & loss function plotting using different hyperparameters\n",
    "- [Testing](#Testing)\n",
    "- [Summary](#Summary)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "# from pandas_profiling import ProfileReport\n",
    "import sweetviz as sv\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, Normalizer, LabelEncoder #, OneHotEncoder\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import cross_validate, LeavePOut, KFold #, train_test_split\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "# plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "source": [
    "Joining `train` & `test` to a single `data` df for an easier time while working on the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv', index_col='Id')\n",
    "test = pd.read_csv('../data/test.csv', index_col='Id')\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "# data\n",
    "\n",
    "# train = pd.get_dummies(data)[:ntrain]\n",
    "# test = pd.get_dummies(data)[:ntest]\n",
    "# test.index = itest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global pipeline\n",
    "pipeline = Pipeline([(\n",
    "    'none',\n",
    "    FunctionTransformer(func=None)\n",
    ")])\n",
    "# use pipeline.steps.append() for adding steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendToPipeline(pipeline, func, func_name=None):\n",
    "    if func_name == None:\n",
    "        func_name = func.__name__\n",
    "    \n",
    "    names = []\n",
    "    for (n,f) in pipeline.steps:\n",
    "        names += [n]\n",
    "    \n",
    "    if func_name not in names:\n",
    "        pipeline.steps.append((\n",
    "            func_name,\n",
    "            FunctionTransformer(func)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start thing off, we can use ~~pandas_profiling~~ sweetviz library to get an overview of the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProfileReport(train, minimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = sv.analyze(data)\n",
    "# report.show_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the target value's distribution.  \n",
    "It seems to be normally distributed and a bit right skewed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the fitted parameters used by the function\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "(mu, sigma) = ( round(item, 2) for item in stats.norm.fit( data['SalePrice'][:ntrain] ) )\n",
    "\n",
    "display(Markdown(f'$\\mu$ = {mu}'))\n",
    "display(Markdown(f'$\\sigma$ = {sigma}'))\n",
    "\n",
    "# plot the distribution\n",
    "sns.distplot(\n",
    "    data['SalePrice'][:ntrain],\n",
    "    kde_kws = {'color': '#4C4C4C'}\n",
    ")\n",
    "plt.legend(\n",
    "    # [f'Normal dist N($\\mu=${mu}, $\\sigma=${sigma})'],\n",
    "    [f't ~ $N(\\mu=${mu}, $\\sigma=${sigma}$)$'],\n",
    "    fontsize = 'x-large'\n",
    ")\n",
    "# plt.ylabel('Frequency')\n",
    "plt.title('SalePrice Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is a correlation heatmap.  \n",
    "\n",
    "Since we have so many different feature already in our dataset, we should choose only the best features.  \n",
    "Using the following heatmap we can choose the feature that have the best correlation to the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "\n",
    "plt.figure(figsize=(30, 12))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    cmap = 'coolwarm',\n",
    "    annot = True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more graph that depict the correlation of several features to the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.boxplot(\n",
    "    x = 'GarageCars',\n",
    "    y = 'SalePrice',\n",
    "    data = data\n",
    ")\n",
    "plt.title('GarageCars / SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "sns.barplot(\n",
    "    x = 'FullBath',\n",
    "    y = 'SalePrice',\n",
    "    data = data\n",
    ")\n",
    "plt.title('FullBath / SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "# sns.boxplot(\n",
    "#     x = 'OverallQual',\n",
    "#     y = 'SalePrice',\n",
    "#     data = train\n",
    "# )\n",
    "# plt.title('OverallQual / SalePrice')\n",
    "# plt.show()\n",
    "\n",
    "sns.regplot(\n",
    "    x = 'OverallQual',\n",
    "    y = 'SalePrice',\n",
    "    data = data,\n",
    "    line_kws = {\n",
    "        'color': '#E37D3D' # '#B55D60'\n",
    "    }\n",
    ")\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.title('OverallQual / SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "source": [
    "Before we can do any kind of feature engineering we need to clean our dataset.  \n",
    "\n",
    "The first to do here is to have a general idea of the total and percentage of missing data in each column.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def NAs(data):\n",
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing %': data_na})\n",
    "missing_data.head()\n",
    "# return missing_data\n",
    "\n",
    "# NAs(train).head()"
   ]
  },
  {
   "source": [
    "There are lots of ways to deal with missing values.  \n",
    "We can drop the columns with too many missing values or impute them instead.  \n",
    "\n",
    "I don't really like to drop any columns since we lose data that way, so we'll impute missing values and maybe drop just one unnecessary column."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_transfrom(data):\n",
    "    global cols_non_numeric\n",
    "    global cols_numeric\n",
    "    cols_numeric = []\n",
    "    cols_non_numeric = []\n",
    "    cpy = pd.DataFrame(data)\n",
    "    cpy[\"PoolQC\"] = cpy[\"PoolQC\"].fillna(\"None\")\n",
    "    cpy[\"MiscFeature\"] = cpy[\"MiscFeature\"].fillna(\"None\")\n",
    "    cpy[\"Alley\"] = cpy[\"Alley\"].fillna(\"None\")\n",
    "    cpy[\"Fence\"] = cpy[\"Fence\"].fillna(\"None\")\n",
    "    cpy[\"FireplaceQu\"] = cpy[\"FireplaceQu\"].fillna(\"None\")\n",
    "    cpy[\"LotFrontage\"] = cpy.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "        cpy[col] = cpy[col].fillna('None')\n",
    "    for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "        cpy[col] = cpy[col].fillna(0)\n",
    "    for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "        cpy[col] = cpy[col].fillna(0)\n",
    "    for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "        cpy[col] = cpy[col].fillna('None')\n",
    "    cpy[\"MasVnrType\"] = cpy[\"MasVnrType\"].fillna(\"None\")\n",
    "    cpy[\"MasVnrArea\"] = cpy[\"MasVnrArea\"].fillna(0)\n",
    "    cpy['MSZoning'] = cpy['MSZoning'].fillna(cpy['MSZoning'].mode()[0])\n",
    "    cpy = cpy.drop(['Utilities'], axis=1)\n",
    "    cpy[\"Functional\"] = cpy[\"Functional\"].fillna(\"Typ\")\n",
    "    cpy['Electrical'] = cpy['Electrical'].fillna(cpy['Electrical'].mode()[0])\n",
    "    cpy['KitchenQual'] = cpy['KitchenQual'].fillna(cpy['KitchenQual'].mode()[0])\n",
    "    cpy['Exterior1st'] = cpy['Exterior1st'].fillna(cpy['Exterior1st'].mode()[0])\n",
    "    cpy['Exterior2nd'] = cpy['Exterior2nd'].fillna(cpy['Exterior2nd'].mode()[0])\n",
    "    cpy['SaleType'] = cpy['SaleType'].fillna(cpy['SaleType'].mode()[0])\n",
    "    cpy['MSSubClass'] = cpy['MSSubClass'].fillna(\"None\")\n",
    "\n",
    "    # cols_numeric = []\n",
    "    # cols_non_numeric = []\n",
    "    for c in cpy.columns:\n",
    "        if cpy[c].dtype == object:\n",
    "            cols_non_numeric += [c]\n",
    "            # lbl = LabelEncoder()\n",
    "            # cpy[c] = lbl.fit_transform(cpy[c].values.tolist())\n",
    "            cpy[c] = cpy[c].astype('category')\n",
    "            # cpy[c] = cpy[c].astype('category').cat.codes.astype('category')\n",
    "        else:\n",
    "            if 'qual' in c.lower() or 'cond' in c.lower() or 'type' in c.lower() or 'class' in c.lower():\n",
    "                cols_non_numeric += [c]\n",
    "                cpy[c] = cpy[c].astype('category')\n",
    "            else:\n",
    "                cols_numeric += [c]\n",
    "    # print('Shape data: {}'.format(cpy.shape))\n",
    "    return cpy\n",
    "\n",
    "# data_filled = fill_and_transfrom(data)\n",
    "\n",
    "appendToPipeline(pipeline, fill_and_transfrom)\n",
    "data_filled = pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "source": [
    "One feature that we can add is `TotalSqfootage`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTotalSq(data):\n",
    "    cpy = pd.DataFrame(data)\n",
    "    cpy['TotalSF'] = cpy['TotalBsmtSF'] + cpy['1stFlrSF'] + cpy['2ndFlrSF']\n",
    "    return cpy\n",
    "\n",
    "appendToPipeline(pipeline, addTotalSq)\n",
    "data_filled = pipeline.fit_transform(data)"
   ]
  },
  {
   "source": [
    "~~For an affective ML model we're going to need to standardize the features by removing the mean and scaling to unit variance.~~  \n",
    "\n",
    "~~The standard score of a sample `x` is calculated as:~~  \n",
    "\n",
    "~~z = \\frac{(x - \\mu)}{std}~~"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "For an affective ML model we're going to need to normalize the features by removing the mean and scaling to unit variance.  \n",
    "\n",
    "The normalization of a sample `x` is calculated as follows:\n",
    "$$\n",
    "norm(x_i) = \\frac{x_i − min(X)}{max(X) − min(X)}\n",
    "$$\n",
    "\n",
    "We would transfrom each column except for the target, since we need it's real values as predictions & validations.  \n",
    "\n",
    "We can normalize the X vector while fitting the data to the model using:\n",
    "```py\n",
    "LinearRegression.fit(X, y, normalize=True)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Now we can split our `data` back into `train` and `test`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('./data/train.csv', index_col='Id')\n",
    "# test = pd.read_csv('./data/test.csv', index_col='Id')\n",
    "\n",
    "appendToPipeline(pipeline, lambda data: pd.get_dummies(data), 'get_dummies')\n",
    "\n",
    "# train_dummy = pd.get_dummies(data_filled)[:ntrain]\n",
    "# test_dummy = pd.get_dummies(data_filled)[:ntest]\n",
    "# test_dummy.index = test.index\n",
    "\n",
    "# train_no_dummy = data_filled[:ntrain]\n",
    "# test_no_dummy = data_filled[:ntest]\n",
    "\n",
    "train_dummy = pipeline.fit_transform(train)\n",
    "test_dummy = pipeline.fit_transform(test)\n",
    "\n",
    "display(train_dummy.head())\n",
    "display(train_dummy['SalePrice'].head())\n",
    "display(train_dummy.dtypes)\n",
    "\n",
    "# display(test_dummy.head())"
   ]
  },
  {
   "source": [
    "## Training & Model Comparing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "~~We're going to train our model on different sizes of train and validation sets.  \n",
    "After that we will see which size of train set is the best.~~"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "As hyper-paramater testing we will choose different sized feature sets.  \n",
    "\n",
    "That way we could control the polynomial degree of our model, which in turn will affect the model's flexibility."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_k(start, step, length):\n",
    "    lst = []\n",
    "    for i in range(length):\n",
    "        lst += [start + (step*i)]\n",
    "    return lst\n",
    "    \n",
    "    # def inner(start, step, size):\n",
    "    #     curr = start\n",
    "    #     while size != 0:\n",
    "    #         yield curr\n",
    "    #         curr += step\n",
    "    #         size -= 1\n",
    "    # return [i for i in inner(start, step, size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = gen_k(start=16, step=6, length=12)\n",
    "# k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SalePrice correlation matrix\n",
    "train_dummy = pipeline.fit_transform(train)\n",
    "corr = train_dummy.corr()\n",
    "feats = []\n",
    "\n",
    "# k = number of diffrent feature sets to choose (polynomial degree)\n",
    "k = gen_k(start=16, step=6, length=12) # => [16, 22, ..., 82]\n",
    "\n",
    "# picking the top correlated features, not including the target\n",
    "for n in k:\n",
    "    # cols = np.abs(corr).nlargest(n+1, 'SalePrice')['SalePrice'].index.tolist()\n",
    "    cols = corr.nlargest(n+1, 'SalePrice')['SalePrice'].index.tolist()\n",
    "    cols.remove('SalePrice')\n",
    "    feats += [cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats[0]"
   ]
  },
  {
   "source": [
    "~~Let's try the sklearn backwards feature selection method, `RFE`.~~\n",
    "\n",
    "The feature selection based on correletion to the target worked much better than `RFE`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # est = SGDRegressor(learning_rate='optimal')\n",
    "# # est = SGDRegressor()\n",
    "# est = LinearRegression(normalize=True)\n",
    "\n",
    "# data = pipeline.fit_transform(train)\n",
    "# y = data['SalePrice']\n",
    "# X = data.drop(columns=['SalePrice'])\n",
    "# feats = []\n",
    "\n",
    "# # k = number of diffrent feature sets to choose (polynomial degree)\n",
    "# k = gen_k(start=10, step=7, length=4) # => [10, 17, 24, 31, 38, 45, 52, 59, 66, 73]\n",
    "\n",
    "# for n in tqdm(k):\n",
    "#     rfe = RFE(\n",
    "#         estimator = est,\n",
    "#         n_features_to_select = n\n",
    "#     )\n",
    "#     rfe.fit_transform(X, y)\n",
    "#     # feats += [ X.columns[rfe.support_].tolist() ]\n",
    "#     feats += [ X.columns[rfe.support_ == False].tolist() ]\n",
    "\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one of the different heatmaps we chose in the last cell\n",
    "plt.figure(figsize=(24,11))\n",
    "sns.set(font_scale=1.25)\n",
    "\n",
    "cols = ['SalePrice'] + feats[1]\n",
    "cm = np.corrcoef(train_dummy[cols].values.T)\n",
    "hm = sns.heatmap(\n",
    "    cm,\n",
    "    cbar = True,\n",
    "    annot = True,\n",
    "    square = True,\n",
    "    fmt = '.2f',\n",
    "    cmap = 'coolwarm',\n",
    "    yticklabels = cols,\n",
    "    xticklabels = cols,\n",
    "    # title = f'Top {len(feats)-1} Correlated Features',\n",
    "    annot_kws = {'size': 11}\n",
    ")\n",
    "\n",
    "hm.set(title=f'Top {len(cols)-1} Correlated Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrmse(y_true, y_pred, squared):\n",
    "    return metrics.mean_squared_error(np.log(y_true), np.log(y_pred), squared=squared)\n",
    "\n",
    "lrmse_socrer = make_scorer(lrmse, greater_is_better=False, squared=True)\n",
    "lmse_socrer = make_scorer(lrmse, greater_is_better=False, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ESTIMATORS ###\n",
    "estimators = []\n",
    "# estimators += [SGDRegressor(learning_rate='optimal')]\n",
    "# estimators += [SGDRegressor()]\n",
    "# estimators += [LinearRegression(normalize=True)]\n",
    "# estimators += [{'model':Ridge, 'kws':{'normalize':True, 'alpha':0.5}}]\n",
    "estimators += [{'model':Ridge, 'kws':{'normalize':True, 'alpha':0.29}}]\n",
    "estimators += [{'model':Ridge, 'kws':{'normalize':True, 'alpha':0.2}}]\n",
    "# estimators += [{'model':Ridge, 'kws':{'normalize':True, 'alpha':0.05}}]\n",
    "# estimators += [ElasticNet(normalize=True, alpha=0.5)]\n",
    "# estimators += [Lasso(normalize=True, alpha=0.5)]\n",
    "# estimators += [Lasso(normalize=True, alpha=0.2)]\n",
    "### ESTIMATORS ###\n",
    "\n",
    "### CV METHODS ###\n",
    "# l1o = LeavePOut(p=1)\n",
    "# fivefold = KFold(n_splits=5, shuffle=True, random_state=101)\n",
    "tenfold = KFold(n_splits=10, shuffle=True, random_state=101)\n",
    "### CV METHODS ###\n",
    "\n",
    "scores = {}\n",
    "# scores = dict()\n",
    "\n",
    "for d in estimators:\n",
    "    model = d['model']\n",
    "    kws = d['kws']\n",
    "    est = model(**kws)\n",
    "    d['est'] = est\n",
    "\n",
    "    est_name = \"\"\n",
    "    for i in str(est.__repr__).strip(\"<>'\").split(' ')[-2:]:\n",
    "        est_name += i.strip('of ')\n",
    "    scores[est_name] = []\n",
    "\n",
    "    for cols in tqdm(feats):\n",
    "        data = pipeline.fit_transform(train)\n",
    "        X = data[cols]\n",
    "        y = data['SalePrice']\n",
    "        res = cross_validate(\n",
    "            X = X,\n",
    "            y = y,\n",
    "            estimator = est,\n",
    "            cv = tenfold.split(X),\n",
    "            # cv = fivefold.split(X),\n",
    "            # cv = l1o.split(X),\n",
    "            return_train_score = True,\n",
    "            return_estimator = True,\n",
    "            scoring = {\n",
    "                'neg_LRMSE': lrmse_socrer,\n",
    "                'neg_LMSE': lmse_socrer,\n",
    "                'neg_MSE': 'neg_mean_squared_error',\n",
    "                # 'neg_MAE': 'neg_mean_absolute_error',\n",
    "                # 'neg_MSLE': 'neg_mean_squared_log_error'\n",
    "            }\n",
    "        )\n",
    "        res['feats'] = cols\n",
    "        scores[est_name] += [res]\n",
    "\n",
    "print('\\n\\ndone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_names = list(scores.keys())\n",
    "print('estimators:\\n', est_names)\n",
    "print('\\nscores:\\n', list(scores[est_names[0]][0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defs for easier access to loss function\n",
    "# MSE = 'neg_mean_squared_error'\n",
    "# LRMSE = 'neg_log_root_mean_squared_error'\n",
    "# MAE = 'neg_mean_absolute_error'\n",
    "# MSLE = 'neg_mean_squared_log_error'\n",
    "\n",
    "MSE = 'MSE'\n",
    "LRMSE = 'LRMSE'\n",
    "LMSE = 'LMSE'\n",
    "\n",
    "# losses = [MSE, RMSE, MAE, MSLE]\n",
    "# losses = [MSE, LRMSE, MAE, MSLE]\n",
    "losses = [MSE, LRMSE, LMSE]"
   ]
  },
  {
   "source": [
    "Now we're going to need to choose the best estimator among the estimators we tried.  \n",
    "\n",
    "Let's go over them in a clean df, each score in this df is the mean of all scores that estimator got."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = [f'test_{loss}' for loss in losses]\n",
    "estimators_df = pd.DataFrame(columns=cols, index=est_names)\n",
    "\n",
    "for est in est_names:\n",
    "    s = scores[est]\n",
    "    scores_df = pd.DataFrame(s)\n",
    "\n",
    "    for loss in losses:\n",
    "        estimators_df[f'test_{loss}'][est] = np.mean(-scores_df[f'test_neg_{loss}'].apply(np.mean))\n",
    "\n",
    "estimators_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll choose the best estimator\n",
    "\n",
    "# loss = [MSE, 'MSE']\n",
    "# loss = [LRMSE, 'LRMSE']\n",
    "loss = [LMSE, 'LMSE']\n",
    "\n",
    "best_score = np.min(estimators_df[f'test_{loss[0]}'])\n",
    "best_est = estimators_df[ estimators_df[f'test_{loss[0]}']==best_score ].index[0]\n",
    "\n",
    "print('the best estimator is:\\n', best_est)"
   ]
  },
  {
   "source": [
    "Let's choose one of the models and take a look of what we got so far.  \n",
    "\n",
    "We could plot the difference between the predictions and the true value of the target.  \n",
    "In a perfect world we would get a 45deg function ($f_{(x)}=x$ ➜ $y_{pred}=y_{true}$)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "def plot_predictions(data, feats, model, title=None, axis=None):\n",
    "    if title == None:\n",
    "        title = f'deg={len(feats)}'\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'y_true': data['SalePrice'],\n",
    "        'y_pred': model.predict(data[feats])\n",
    "    })\n",
    "    g = sns.regplot(\n",
    "        x = 'y_true',\n",
    "        y = 'y_pred',\n",
    "        data = df,\n",
    "        line_kws = {'color': '#B55D60'},\n",
    "        scatter_kws = {'edgecolor': 'white'},\n",
    "        ax = axis\n",
    "    )\n",
    "    g.set(title = title)\n",
    "    return g\n",
    "\n",
    "s = random.choice(scores[best_est])\n",
    "cols = s['feats']\n",
    "model = random.choice(s['estimator'])\n",
    "train_dummy = pipeline.fit_transform(train)\n",
    "\n",
    "plot_predictions(train_dummy, cols, model, title=f'Estimator = {best_est}\\nPoly_Degree = {len(cols)}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=math.ceil(len(k)/3), ncols=3, sharex=True, sharey=True) ##sharex=True, sharey=True##\n",
    "fig.set_size_inches(17, 22)\n",
    "# plt.figure(figsize=(16,16))\n",
    "fig.text(0.5, 0.04, 'y_true', ha='center')\n",
    "fig.text(0.04, 0.5, 'y_pred', va='center', rotation='vertical')\n",
    "axs = axs.flatten().tolist()\n",
    "\n",
    "train_dummy = pipeline.fit_transform(train)\n",
    "\n",
    "for s in tqdm(scores[best_est]):\n",
    "    cols = s['feats']\n",
    "    model = random.choice(s['estimator'])\n",
    "\n",
    "    g = plot_predictions(train_dummy, cols, model, title=f'Estimator = {best_est}\\nPoly_Degree = {len(cols)}', axis=axs.pop(0))\n",
    "    g.set(xlabel='', ylabel='')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores[best_est]).drop(columns=['fit_time', 'score_time', 'estimator'])\n",
    "\n",
    "for loss in losses:\n",
    "    scores_df[f'test_{loss}'] = -scores_df[f'test_neg_{loss}'].apply(np.mean)\n",
    "    scores_df[f'train_{loss}'] = -scores_df[f'train_neg_{loss}'].apply(np.mean)\n",
    "    scores_df = scores_df.drop(columns=[f'test_neg_{loss}', f'train_neg_{loss}'])\n",
    "\n",
    "# scores_df[f'test_{RMSE}'] = np.sqrt(scores_df[f'test_{MSE}'])\n",
    "# scores_df[f'train_{RMSE}'] = np.sqrt(scores_df[f'train_{MSE}'])\n",
    "\n",
    "scores_df['deg'] = scores_df['feats'].apply(len)\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss, x, y, data=scores_df):\n",
    "    sns.lineplot(\n",
    "        x = 'deg',\n",
    "        y = f'{y}_{loss[0]}',\n",
    "        data = scores_df,\n",
    "        # data = np.log(scores_df[['deg', f'{y}_{loss[0]}']]),\n",
    "        marker = 'o'\n",
    "    )\n",
    "\n",
    "    # plt.title('Err Plot')\n",
    "    plt.xlabel('Degree of Polynomial')\n",
    "    plt.ylabel(f'Loss = {loss[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "# loss = [MSE, 'MSE']\n",
    "# loss = [LRMSE, 'LRMSE']\n",
    "loss = [LMSE, 'LMSE']\n",
    "# loss = [MAE, 'MAE']\n",
    "# loss = [MSLE, 'MSLE']\n",
    "\n",
    "plot_loss(\n",
    "    loss,\n",
    "    x = 'deg',\n",
    "    y = 'train',\n",
    "    data = scores_df\n",
    ")\n",
    "\n",
    "plot_loss(\n",
    "    loss,\n",
    "    x = 'deg',\n",
    "    y = 'test',\n",
    "    data = scores_df\n",
    ")\n",
    "\n",
    "plt.title(f'Estimator = {best_est}')\n",
    "plt.legend(['train', 'test'], fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "By looking at the graph above we can notice that the best model we fitted had around 80 features.  \n",
    "\n",
    "Let's choose that model and try and predict the actual test data from kaggle."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = MSE\n",
    "loss = LMSE\n",
    "\n",
    "# get the best score's feature list\n",
    "best_score = min(scores_df[f'test_{loss}'])\n",
    "i = scores_df[scores_df[f'test_{loss}'] == best_score].index.tolist()[0]\n",
    "cols = scores[best_est][i]['feats']\n",
    "\n",
    "# get a clean train & test DFs\n",
    "train_dummy = pipeline.fit_transform(train)\n",
    "test_dummy = pipeline.fit_transform(test)\n",
    "\n",
    "# train the model on the entire train set\n",
    "# for i,est in enumerate(estimators):\n",
    "for d in estimators:\n",
    "    est = d['est']\n",
    "    if best_est in str(est.__repr__):\n",
    "        break\n",
    "# est = estimators[i]\n",
    "model = est.fit(train_dummy[cols], train_dummy['SalePrice'])\n",
    "\n",
    "# predict the test set\n",
    "y_pred = model.predict(test_dummy[cols])\n",
    "\n",
    "pred = pd.DataFrame(\n",
    "    y_pred,\n",
    "    columns = ['SalePrice'],\n",
    "    index = test.index\n",
    ")\n",
    "\n",
    "display(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fitted parameters used by the function\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "(mu, sigma) = ( round(item, 2) for item in stats.norm.fit(pred) )\n",
    "\n",
    "display(Markdown(f'$\\mu$ = {mu}'))\n",
    "display(Markdown(f'$\\sigma$ = {sigma}'))\n",
    "\n",
    "# plot the distribution\n",
    "sns.distplot(\n",
    "    pred,\n",
    "    kde_kws = {'color': '#4C4C4C'}\n",
    ")\n",
    "plt.legend(\n",
    "    [f'y_pred ~ $N(\\mu=${mu}, $\\sigma=${sigma}$)$'],\n",
    "    fontsize = 'x-large'\n",
    ")\n",
    "# plt.ylabel('Frequency')\n",
    "plt.title('Prediction Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loss = MSE\n",
    "# loss = LMSE\n",
    "\n",
    "# # get the best score's feature list\n",
    "# best_score = min(scores_df[f'test_{loss}'])\n",
    "# i = scores_df[scores_df[f'test_{loss}'] == best_score].index.tolist()[0]\n",
    "# cols = scores[best_est][i]['feats']\n",
    "\n",
    "# # get a clean train & test DFs\n",
    "# # train_dummy = pipeline.fit_transform(train)\n",
    "# test_dummy = pipeline.fit_transform(test)\n",
    "\n",
    "# # train the model on the entire train set\n",
    "# # for i,est in enumerate(estimators):\n",
    "# # for est in estimators:\n",
    "# #     if best_est in str(est.__repr__):\n",
    "# #         break\n",
    "# # est = estimators[i]\n",
    "# # model = est.fit(train_dummy[cols], train_dummy['SalePrice'])\n",
    "\n",
    "# # scores[best_est][i]['estimator']\n",
    "\n",
    "# # predict the test set\n",
    "# preds = pd.DataFrame(columns=[i for i in range(len(scores[best_est][i]['estimator']))])\n",
    "# for i,model in  enumerate(scores[best_est][i]['estimator']):\n",
    "#     preds[i] = model.predict(test_dummy[cols])\n",
    "# preds\n",
    "\n",
    "# y_pred = []\n",
    "# for i in preds.index:\n",
    "#     y_pred += [np.mean(preds.iloc[i])]\n",
    "\n",
    "# pred = pd.DataFrame(\n",
    "#     y_pred,\n",
    "#     columns = ['SalePrice'],\n",
    "#     index = test.index\n",
    "# )\n",
    "\n",
    "# display(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('pred.csv')"
   ]
  },
  {
   "source": [
    "## Summary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Screenshots"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![submissions](./screenshots/submissions.png)  \n",
    "\n",
    "![leaderboards](./screenshots/leaderboards.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Conclusions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}